{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Fraud Detection with DGL on Amazon SageMaker\n",
    "\n",
    "This notebook shows an end to end pipeline to train a fraud detection model using graph neural networks. \n",
    "\n",
    "First, we process the raw dataset to prepare the features and extract the interactions in the dataset that will be used to construct the graph. \n",
    "\n",
    "Then, we create a launch a training job using the SageMaker framework estimator to train a graph neural network model with DGL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Obtaining file:///root/fraud-detection-workshop/4.%20Advanced/sagemaker_graph_fraud_detection\n",
      "Installing collected packages: sagemaker-graph-fraud-detection\n",
      "  Running setup.py develop for sagemaker-graph-fraud-detection\n",
      "Successfully installed sagemaker-graph-fraud-detection-1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!bash setup.sh\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker_graph_fraud_detection import config, container_build\n",
    "\n",
    "role = config.role\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites to build and deploy custom container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach a trust policy to the SageMaker execution IAM role for AWS CodeBuild. This ensures that in addition to Amazon SageMaker, AWS CodeBuild can also assume this role so that it could automate building docker images\n",
    "\n",
    "go to SageMaker Studio, then click on the SageMaker Studio “User name” as shown below\n",
    "\n",
    "![setup](images/1.png)\n",
    "\n",
    "copy the name of the SageMaker Studio execution role\n",
    "\n",
    "\n",
    "![setup](images/2.png)\n",
    "\n",
    "go to IAM, then click on “Roles”, then search roles by the name of the execution role you copied above, then click on the only item that appears under “Role name”\n",
    "\n",
    "![setup](images/3.png)\n",
    "\n",
    "click on the “Trust relationships” tab, then click on “Edit trust relationship”\n",
    "\n",
    "![setup](images/4.png)\n",
    "\n",
    "in the “Edit trust relationship” text area, paste the code from https://github.com/aws-samples/amazon-sagemaker-immersion-day/blob/master/iam-policy-sm-trust.txt, then click on “Update Trust Policy”\n",
    "\n",
    "![setup](images/5.png)\n",
    "\n",
    "The “Trust relationship” tab should now show 2 entries under “Trusted entities”\n",
    "\n",
    "![setup](images/6.png)\n",
    "\n",
    "an additional IAM policy the SageMaker execution IAM role to allow it to build the docker image using AWS CodeBuild\n",
    "\n",
    "* click on the “Permissions” tab in IAM roles, then click on “Add inline policy”\n",
    "![setup](images/7.png)\n",
    "\n",
    "in the “Create policy” page click on the “JSON” tab, then copy the contents of the file https://github.com/aws-samples/amazon-sagemaker-immersion-day/blob/master/iam-policy-sm-cb.txt and paste it in the text area replacing the default text, then click on “Review policy”. Follow the remaining steps to create an inline policy\n",
    "\n",
    "![setup](images/8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload raw data to S3\n",
    "\n",
    "The dataset we use is the [IEEE-CIS Fraud Detection dataset](https://www.kaggle.com/c/ieee-fraud-detection/data?select=train_transaction.csv) which is a typical example of financial transactions dataset that many companies have. The dataset consists of two tables:\n",
    "\n",
    "* **Transactions**: Records transactions and metadata about transactions between two users. Examples of columns include the product code for the transaction and features on the card used for the transaction. \n",
    "* **Identity**: Contains information about the identity users performing transactions. Examples of columns here include the device type and device ids used.\n",
    "\n",
    "We will go over the specific data schema in subsequent cells but now let's move the raw data to a convenient location in the S3 bucket for this proejct, where it will be picked up by the preprocessing job and training job.\n",
    "\n",
    "If you would like to use your own dataset for this demonstration. Replace the `raw_data_location` with the s3 path or local path of your dataset, and modify the data preprocessing step as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy: s3://sagemaker-solutions-us-west-2/Fraud-detection-in-financial-networks/data/identity.csv to s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/raw-data/identity.csv\n",
      "copy: s3://sagemaker-solutions-us-west-2/Fraud-detection-in-financial-networks/data/transaction.csv to s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/raw-data/transaction.csv\n"
     ]
    }
   ],
   "source": [
    "# Replace with an S3 location or local path to point to your own dataset\n",
    "raw_data_location = 's3://sagemaker-solutions-us-west-2/Fraud-detection-in-financial-networks/data'\n",
    "\n",
    "session_prefix = 'dgl-fraud-detection'\n",
    "input_data = 's3://{}/{}/{}'.format(config.solution_bucket, session_prefix, config.s3_data_prefix)\n",
    "\n",
    "!aws s3 cp --recursive $raw_data_location $input_data\n",
    "\n",
    "# Set S3 locations to store processed data for training and post-training results and artifacts respectively\n",
    "train_data = 's3://{}/{}/{}'.format(config.solution_bucket, session_prefix, config.s3_processing_output)\n",
    "train_output = 's3://{}/{}/{}'.format(config.solution_bucket, session_prefix, config.s3_train_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build container for Preprocessing and Feature Engineering\n",
    "\n",
    "Data preprocessing and feature engineering is an important component of the ML lifecycle, and Amazon SageMaker Processing allows you to do these easily on a managed infrastructure. First, we'll create a lightweight container that will serve as the environment for our data preprocessing. \n",
    "\n",
    "The Dockerfile that defines the container is shown below and it only contains the pandas package as a dependency but it can also be easily customized to add in more dependencies if your data preprocessing job requires it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mFROM\u001b[39;49;00m \u001b[33mpython:3.7-slim-buster\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mRUN\u001b[39;49;00m pip3 install \u001b[31mpandas\u001b[39;49;00m==\u001b[34m0\u001b[39;49;00m.24.2\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mPYTHONUNBUFFERED\u001b[39;49;00m=TRUE\n",
      "\n",
      "\u001b[34mENTRYPOINT\u001b[39;49;00m [\u001b[33m\"python3\"\u001b[39;49;00m]\n"
     ]
    }
   ],
   "source": [
    "!pygmentize datapreprocessing/container/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install sagemaker-studio-image-build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll run a simple script to build a container image using the Dockerfile, and push the image to Amazon ECR. The container image will have a unique URI which the SageMaker Processing job executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "cd datapreprocessing/container\n",
    "\n",
    "sm-docker build .  --repository sagemaker-dgl:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the uri from the above command and set it to below variable\n",
    "ecr_repository_uri = '365792799466.dkr.ecr.ap-southeast-1.amazonaws.com/sagemaker-dgl:latest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Preprocessing job with Amazon SageMaker Processing\n",
    "\n",
    "The script we have defined at `data-preprocessing/graph_data_preprocessor.py` performs data preprocessing and feature engineering transformations on the raw data. We provide a general processing framework to convert a relational table to heterogeneous graph edgelists based on the column types of the relational table. Some of the data transformation and feature engineering techniques include:\n",
    "\n",
    "* Performing numerical encoding for categorical variables and logarithmic transformation for transaction amount\n",
    "* Constructing graph edgelists between transactions and other entities for the various relation types\n",
    "\n",
    "The inputs to the data preprocessing script are passed in as python command line arguments. All the columns in the relational table are classifed into one of 3 types for the purposes of data transformation: \n",
    "\n",
    "* **Identity columns** `--id-cols`: columns that contain identity information related to a user or transaction for example IP address, Phone Number, device identifiers etc. These column types become node types in the heterogeneous graph, and the entries in these columns become the nodes. The column names for these column types need to passed in to the script.\n",
    "\n",
    "* **Categorical columns** `--cat-cols`: columns that correspond to categorical features for a user's age group or whether a provided address matches with an address on file. The entries in these columns undergo numerical feature transformation and are used as node attributes in the heterogeneous graph. The columns names for these column types also needs to be passed in to the script\n",
    "\n",
    "* **Numerical columns**: columns that correspond to numerical features like how many times a user has tried a transaction and so on. The entries here are also used as node attributes in the heterogeneous graph. The script assumes that all columns in the tables that are not identity columns or categorical columns are numerical columns\n",
    "\n",
    "In order to adapt the preprocessing script to work with data in the same format, you can simply change the python arguments used in the cell below to a comma seperate string for the column names in your dataset. If your dataset is in a different format, then you will also have to modify the preprocessing script at `data-preprocessing/graph_data_preprocessor.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'session' will be renamed to 'sagemaker_session' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-dgl-2021-08-24-04-48-36-091\n",
      "Inputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/raw-data', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-ap-southeast-1-365792799466/sagemaker-dgl-2021-08-24-04-48-36-091/input/code/graph_data_preprocessor.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'output-1', 'S3Output': {'S3Uri': 's3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "..............................\u001b[34m2021-08-24 04:53:27,709 INFO __main__: Shape of transaction data is (590540, 394)\u001b[0m\n",
      "\u001b[34m2021-08-24 04:53:27,712 INFO __main__: # Tagged transactions: 590540\u001b[0m\n",
      "\u001b[34m2021-08-24 04:53:28,372 INFO __main__: Shape of identity data is (144233, 41)\u001b[0m\n",
      "\u001b[34m2021-08-24 04:53:28,415 INFO __main__: Percent fraud for train transactions: 3.5135215226741625\u001b[0m\n",
      "\u001b[34m2021-08-24 04:53:28,426 INFO __main__: Percent fraud for test transactions: 3.4409184813899145\u001b[0m\n",
      "\u001b[34m2021-08-24 04:53:28,478 INFO __main__: Percent fraud for all transactions: 3.499000914417313\u001b[0m\n",
      "\u001b[34m2021-08-24 04:53:28,597 INFO __main__: Wrote test to file: /opt/ml/processing/output/test.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:53:28,598 INFO __main__: Categorical columns: ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']\u001b[0m\n",
      "\u001b[34m2021-08-24 04:53:33,839 INFO __main__: Transformed feature columns: ['TransactionID', 'TransactionAmt', 'dist1', 'dist2', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D7', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40', 'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50', 'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90', 'V91', 'V92', 'V93', 'V94', 'V95', 'V96', 'V97', 'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129', 'V130', 'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137', 'V138', 'V139', 'V140', 'V141', 'V142', 'V143', 'V144', 'V145', 'V146', 'V147', 'V148', 'V149', 'V150', 'V151', 'V152', 'V153', 'V154', 'V155', 'V156', 'V157', 'V158', 'V159', 'V160', 'V161', 'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V168', 'V169', 'V170', 'V171', 'V172', 'V173', 'V174', 'V175', 'V176', 'V177', 'V178', 'V179', 'V180', 'V181', 'V182', 'V183', 'V184', 'V185', 'V186', 'V187', 'V188', 'V189', 'V190', 'V191', 'V192', 'V193', 'V194', 'V195', 'V196', 'V197', 'V198', 'V199', 'V200', 'V201', 'V202', 'V203', 'V204', 'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V211', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V218', 'V219', 'V220', 'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V230', 'V231', 'V232', 'V233', 'V234', 'V235', 'V236', 'V237', 'V238', 'V239', 'V240', 'V241', 'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V248', 'V249', 'V250', 'V251', 'V252', 'V253', 'V254', 'V255', 'V256', 'V257', 'V258', 'V259', 'V260', 'V261', 'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V269', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276', 'V277', 'V278', 'V279', 'V280', 'V281', 'V282', 'V283', 'V284', 'V285', 'V286', 'V287', 'V288', 'V289', 'V290', 'V291', 'V292', 'V293', 'V294', 'V295', 'V296', 'V297', 'V298', 'V299', 'V300', 'V301', 'V302', 'V303', 'V304', 'V305', 'V306', 'V307', 'V308', 'V309', 'V310', 'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318', 'V319', 'V320', 'V321', 'V322', 'V323', 'V324', 'V325', 'V326', 'V327', 'V328', 'V329', 'V330', 'V331', 'V332', 'V333', 'V334', 'V335', 'V336', 'V337', 'V338', 'V339', 'M1_F', 'M1_T', 'M2_F', 'M2_T', 'M3_F', 'M3_T', 'M4_M0', 'M4_M1', 'M4_M2', 'M5_F', 'M5_T', 'M6_F', 'M6_T', 'M7_F', 'M7_T', 'M8_F', 'M8_T', 'M9_F', 'M9_T']\u001b[0m\n",
      "\u001b[34m2021-08-24 04:53:33,839 INFO __main__: Shape of features: (590540, 391)\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:20,997 INFO __main__: Wrote features to file: /opt/ml/processing/output/features.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:22,522 INFO __main__: Wrote labels to file: /opt/ml/processing/output/tags.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:22,527 INFO __main__: Found the following distinct relation types: ['card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'ProductCD', 'addr1', 'addr2', 'P_emaildomain', 'R_emaildomain', 'TransactionID', 'id_01', 'id_02', 'id_03', 'id_04', 'id_05', 'id_06', 'id_07', 'id_08', 'id_09', 'id_10', 'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25', 'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo']\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:23,680 INFO __main__: Shape of identity columns: (590540, 52)\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:25,522 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_card1_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:27,073 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_card2_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:28,627 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_card3_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:29,864 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_card4_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:31,410 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_card5_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:32,613 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_card6_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:33,755 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_ProductCD_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:35,147 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_addr1_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:36,502 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_addr2_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:37,571 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_P_emaildomain_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:37,912 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_R_emaildomain_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:39,609 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_TransactionID_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:40,009 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_01_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:40,432 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_02_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:40,629 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_03_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:40,826 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_04_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:41,199 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_05_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:41,572 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_06_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:41,619 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_07_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:41,666 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_08_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:41,880 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_09_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:42,093 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_10_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:42,492 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_11_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:42,865 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_12_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:43,217 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_13_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:43,453 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_14_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:43,786 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_15_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:44,104 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_16_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:44,502 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_17_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:44,650 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_18_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:45,040 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_19_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:45,435 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_20_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:45,482 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_21_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:45,527 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_22_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:45,591 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_23_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:45,636 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_24_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:45,682 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_25_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:45,728 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_26_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:45,793 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_27_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:46,120 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_28_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:46,457 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_29_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:46,673 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_30_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:47,030 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_31_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:47,259 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_32_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:47,463 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_33_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:47,682 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_34_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:47,999 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_35_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:48,316 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_36_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:48,631 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_37_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:48,953 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_id_38_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:49,293 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_DeviceType_edgelist.csv\u001b[0m\n",
      "\u001b[34m2021-08-24 04:56:49,602 INFO __main__: Wrote edgelist to: /opt/ml/processing/output/relation_DeviceInfo_edgelist.csv\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "\n",
    "script_processor = ScriptProcessor(command=['python3'],\n",
    "                                   image_uri=ecr_repository_uri,\n",
    "                                   role=role,\n",
    "                                   instance_count=1,\n",
    "                                   instance_type='ml.m4.xlarge')\n",
    "\n",
    "script_processor.run(code='datapreprocessing/graph_data_preprocessor.py',\n",
    "                     inputs=[ProcessingInput(source=input_data,\n",
    "                                             destination='/opt/ml/processing/input')],\n",
    "                     outputs=[ProcessingOutput(destination=train_data,\n",
    "                                               source='/opt/ml/processing/output')],\n",
    "                     arguments=['--id-cols', 'card1,card2,card3,card4,card5,card6,ProductCD,addr1,addr2,P_emaildomain,R_emaildomain',\n",
    "                                '--cat-cols','M1,M2,M3,M4,M5,M6,M7,M8,M9'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Results of Data Preprocessing\n",
    "\n",
    "Once the preprocessing job is complete, we can take a look at the contents of the S3 bucket to see the transformed data. We have a set of bipartite edge lists between transactions and different device id types as well as the features, labels and a set of transactions to validate our graph model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Processed Files =====\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/features.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_DeviceInfo_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_DeviceType_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_P_emaildomain_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_ProductCD_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_R_emaildomain_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_TransactionID_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_addr1_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_addr2_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_card1_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_card2_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_card3_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_card4_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_card5_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_card6_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_01_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_02_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_03_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_04_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_05_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_06_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_07_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_08_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_09_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_10_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_11_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_12_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_13_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_14_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_15_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_16_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_17_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_18_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_19_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_20_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_21_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_22_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_23_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_24_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_25_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_26_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_27_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_28_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_29_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_30_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_31_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_32_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_33_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_34_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_35_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_36_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_37_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/relation_id_38_edgelist.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/tags.csv\n",
      "s3://sagemaker-ap-southeast-1-365792799466/dgl-fraud-detection/processed-data/test.csv\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "from sagemaker.s3 import S3Downloader\n",
    "processed_files = S3Downloader.list(train_data)\n",
    "print(\"===== Processed Files =====\")\n",
    "print('\\n'.join(processed_files))\n",
    "\n",
    "# optionally download processed data\n",
    "# S3Downloader.download(train_data, train_data.split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Graph Neural Network with DGL\n",
    "\n",
    "Graph Neural Networks work by learning representation for nodes or edges of a graph that are well suited for some downstream task. We can model the fraud detection problem as a node classification task, and the goal of the graph neural network would be to learn how to use information from the topology of the sub-graph for each transaction node to transform the node's features to a representation space where the node can be easily classified as fraud or not.\n",
    "\n",
    "Specifically, we will be using a relational graph convolutional neural network model (R-GCN) on a heterogeneous graph since we have nodes and edges of different types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "To train the graph neural network, we need to define a few hyperparameters that determine properties such as the class of graph neural network models we will be using, the network architecture and the optimizer and optimization parameters. \n",
    "\n",
    "Here we're setting only a few of the hyperparameters, to see all the hyperparameters and their default values, see `dgl-fraud-detection/estimator_fns.py`. The parameters set below are:\n",
    "\n",
    "* **`nodes`** is the name of the file that contains the `node_id`s of the target nodes and the node features.\n",
    "* **`edges`** is a regular expression that when expanded lists all the filenames for the edgelists\n",
    "* **`labels`** is the name of the file tha contains the target `node_id`s and their labels\n",
    "* **`model`** specify which graph neural network to use, this should be set to `r-gcn`\n",
    "\n",
    "The following hyperparameters can be tuned and adjusted to improve model performance\n",
    "* **batch-size** is the number nodes that are used to compute a single forward pass of the GNN\n",
    "\n",
    "* **embedding-size** is the size of the embedding dimension for non target nodes\n",
    "* **n-neighbors** is the number of neighbours to sample for each target node during graph sampling for mini-batch training\n",
    "* **n-layers** is the number of GNN layers in the model\n",
    "* **n-epochs** is the number of training epochs for the model training job\n",
    "* **optimizer** is the optimization algorithm used for gradient based parameter updates\n",
    "* **lr** is the learning rate for parameter updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph will be constructed using the following edgelists:\n",
      "relation_DeviceInfo_edgelist.csv\n",
      "relation_DeviceType_edgelist.csv\n",
      "relation_P_emaildomain_edgelist.csv\n",
      "relation_ProductCD_edgelist.csv\n",
      "relation_R_emaildomain_edgelist.csv\n",
      "relation_TransactionID_edgelist.csv\n",
      "relation_addr1_edgelist.csv\n",
      "relation_addr2_edgelist.csv\n",
      "relation_card1_edgelist.csv\n",
      "relation_card2_edgelist.csv\n",
      "relation_card3_edgelist.csv\n",
      "relation_card4_edgelist.csv\n",
      "relation_card5_edgelist.csv\n",
      "relation_card6_edgelist.csv\n",
      "relation_id_01_edgelist.csv\n",
      "relation_id_02_edgelist.csv\n",
      "relation_id_03_edgelist.csv\n",
      "relation_id_04_edgelist.csv\n",
      "relation_id_05_edgelist.csv\n",
      "relation_id_06_edgelist.csv\n",
      "relation_id_07_edgelist.csv\n",
      "relation_id_08_edgelist.csv\n",
      "relation_id_09_edgelist.csv\n",
      "relation_id_10_edgelist.csv\n",
      "relation_id_11_edgelist.csv\n",
      "relation_id_12_edgelist.csv\n",
      "relation_id_13_edgelist.csv\n",
      "relation_id_14_edgelist.csv\n",
      "relation_id_15_edgelist.csv\n",
      "relation_id_16_edgelist.csv\n",
      "relation_id_17_edgelist.csv\n",
      "relation_id_18_edgelist.csv\n",
      "relation_id_19_edgelist.csv\n",
      "relation_id_20_edgelist.csv\n",
      "relation_id_21_edgelist.csv\n",
      "relation_id_22_edgelist.csv\n",
      "relation_id_23_edgelist.csv\n",
      "relation_id_24_edgelist.csv\n",
      "relation_id_25_edgelist.csv\n",
      "relation_id_26_edgelist.csv\n",
      "relation_id_27_edgelist.csv\n",
      "relation_id_28_edgelist.csv\n",
      "relation_id_29_edgelist.csv\n",
      "relation_id_30_edgelist.csv\n",
      "relation_id_31_edgelist.csv\n",
      "relation_id_32_edgelist.csv\n",
      "relation_id_33_edgelist.csv\n",
      "relation_id_34_edgelist.csv\n",
      "relation_id_35_edgelist.csv\n",
      "relation_id_36_edgelist.csv\n",
      "relation_id_37_edgelist.csv\n",
      "relation_id_38_edgelist.csv\n"
     ]
    }
   ],
   "source": [
    "edges = \",\".join(map(lambda x: x.split(\"/\")[-1], [file for file in processed_files if \"relation\" in file]))\n",
    "params = {'nodes' : 'features.csv',\n",
    "          'edges': 'relation*',\n",
    "          'labels': 'tags.csv',\n",
    "          'model': 'rgcn',\n",
    "          'num-gpus': 1,\n",
    "          'batch-size': 10000,\n",
    "          'embedding-size': 64,\n",
    "          'n-neighbors': 1000,\n",
    "          'n-layers': 2,\n",
    "          'n-epochs': 10,\n",
    "          'optimizer': 'adam',\n",
    "          'lr': 1e-2\n",
    "        }\n",
    "\n",
    "print(\"Graph will be constructed using the following edgelists:\\n{}\" .format('\\n'.join(edges.split(\",\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Fit SageMaker Estimator\n",
    "\n",
    "With the hyperparameters defined, we can kick off the training job. We will be using the Deep Graph Library (DGL), with MXNet as the backend deep learning framework, to define and train the graph neural network. Amazon SageMaker makes it do this with the Framework estimators which have the deep learning frameworks already setup. Here, we create a SageMaker MXNet estimator and pass in our model training script, hyperparameters, as well as the number and type of training instances we want.\n",
    "\n",
    "We can then `fit` the estimator on the the training data location in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "from time import strftime, gmtime\n",
    "\n",
    "estimator = MXNet(entry_point='train_dgl_mxnet_entry_point.py',\n",
    "                  source_dir='sagemaker_graph_fraud_detection/dgl_fraud_detection',\n",
    "                  role=role, \n",
    "                  train_instance_count=1, \n",
    "                  train_instance_type='ml.p3.2xlarge',\n",
    "                  framework_version=\"1.6.0\",\n",
    "                  py_version='py3',\n",
    "                  hyperparameters=params,\n",
    "                  output_path=train_output,\n",
    "                  code_location=train_output,\n",
    "                  sagemaker_session=sess)\n",
    "\n",
    "training_job_name = \"{}-{}\".format(config.solution_prefix, strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()))\n",
    "estimator.fit({'train': train_data}, job_name=training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training is completed, the training instances are automatically saved and SageMaker stores the trained model and evaluation results to a location in S3."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
